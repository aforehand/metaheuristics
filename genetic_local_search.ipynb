{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticLocalSearch:\n",
    "    \"\"\"A genetic local search metaheuristic.\n",
    "    \n",
    "    Genetic local search generates a population of randomly seeded MLPs\n",
    "    and trains them on given data. It then selects the models with the\n",
    "    lowest loss to serve as 'parents' for the next generation of models.\n",
    "    The 'child' models are generated by randomly choosing between the \n",
    "    weights of pairs of parent models and mutating a small number of \n",
    "    weights. This process of repeated until the specified number of \n",
    "    generations is reached. The model with the lowest loss is returned.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    generations: int (default=100)\n",
    "        The number of times the metaheuristic is applied.\n",
    "    \n",
    "    pop_size: int (default=100)\n",
    "        The number of models in eac generation.\n",
    "        \n",
    "    tournament_size: int (default=5)\n",
    "        The number of models to compare when choosing each parent.\n",
    "        \n",
    "    crossover_type: str (default='uniform')\n",
    "        How weights are chosen when generating child models.\n",
    "        \n",
    "        - If 'uniform', each weight is independently selected from\n",
    "        between the two parents.\n",
    "        - If '2-point', all weights between two randomly selected\n",
    "        indices are chosen from one parent, and all weights outside\n",
    "        those indices are chosen from the other.\n",
    "        \n",
    "    mutation_rate: float (default=0.05)\n",
    "        The percent chance that a weight will be mutated.\n",
    "        \n",
    "    mutation_sd: float (default=0.05)\n",
    "        The standard deviation of the normal distribution from which\n",
    "        the new weight is selected. The distribution is centered on the \n",
    "        old weight value. The default value was chosen to be the same as\n",
    "        the value Keras uses for its Gaussian initializers.\n",
    "        \n",
    "    nodes: int (default=64)\n",
    "        The number of nodes in the hidden layer of each model.\n",
    "        \n",
    "    optimizer: str (default='sgd')\n",
    "        The optimizer used when training each model. Passed to Keras' \n",
    "        model.compile(). See Keras' documentation on optimizers.\n",
    "        \n",
    "    loss: str (default='mean_squared_error')\n",
    "        The loss used when training each model. Passed to Keras' \n",
    "        model.compile().See Keras' documentation on losses.\n",
    "        \n",
    "    metrics: list (default=['mean_squared_error'])\n",
    "        The mertic used when training each model. Passed to Keras' \n",
    "        model.compile(). See Keras' documentation on metrics.\n",
    "        \n",
    "    epochs: int (default=10)\n",
    "        The number of epochs to train each model. Passed to Keras'\n",
    "        model.fit().\n",
    "        \n",
    "    validation_split: float (default=0.2):\n",
    "        The proportion of training data to be used to  evaluate each\n",
    "        model. Passed to Keras' model.fit().\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(generations=100, pop_size=100, tournament_size=5,\n",
    "                 crossover_type='uniform', mutation_rate=0.05, mutation_sd=0.05,\n",
    "                 nodes=64, optimizer='sgd', loss='mean_squared_error', \n",
    "                 metrics=['mean_squared_error'], epochs=10, validation_split=0.2):\n",
    "        self.generations = generations\n",
    "        self.pop_size = pop_size\n",
    "        self.tournament_size = tournament_size\n",
    "        self.crossover_type = crossover_type\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.mutation_sd = mutation_sd\n",
    "        self.nodes = nodes\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        self.epochs = epochs\n",
    "        self.validation_split = validation_split\n",
    "        \n",
    "    def _build_model(self, num_inputs, num_outputs):\n",
    "        \"\"\"Return a MLP model.\"\"\"\n",
    "        model = keras.Sequential([\n",
    "        keras.layers.Dense(self.nodes, \n",
    "                           activation=tf.nn.relu,\n",
    "                           input_shape=(num_inputs,)),\n",
    "        keras.layers.Dense(num_outputs)\n",
    "      ])\n",
    "        model.compile(loss=self.loss,\n",
    "                      optimizer=self.optimizer,\n",
    "                      metrics=self.metrics)\n",
    "        return model\n",
    "\n",
    "    def _initialize_population(self, num_inputs, num_outputs):\n",
    "        \"\"\"Return the initial population of untrained models.\"\"\"\n",
    "        population = set([])\n",
    "        for i in range(self.pop_size):\n",
    "            model = self._build_model(num_inputs, num_outputs)\n",
    "            population.add(model)\n",
    "        return population\n",
    "            \n",
    "    def _local_search(self, population, data, target):\n",
    "        \"\"\"Train each model in the population and return the trained models.\"\"\"\n",
    "        trained_population = set([])\n",
    "        while len(population) > 0:\n",
    "            model = population.pop()\n",
    "            history = model.fit(data, \n",
    "                                target, \n",
    "                                epochs=self.epochs, \n",
    "                                validation_split=self.validation_split, \n",
    "                                verbose=1, \n",
    "                                callbacks=[])\n",
    "            trained_population.add((history.history['val_loss'], model))\n",
    "        return trained_population\n",
    "\n",
    "    def _select_parents(self, population):\n",
    "        \"\"\"Perform tournament selection and return the winners.\"\"\"\n",
    "        parents = set([])\n",
    "        while len(population) > self.tournament_size:\n",
    "            chosen = random.sample(population, self.tournament_size)\n",
    "            parents.add(min(chosen))\n",
    "            population = set([m for m in population if not m in chosen])\n",
    "        if len(population) > 0:\n",
    "            parents.add(min(population))\n",
    "        return parents\n",
    "\n",
    "    def _make_children(self, parents, num_inputs, num_outputs):\n",
    "        \"\"\"Perform crossover and mutation and return the next generation.\"\"\"\n",
    "        children = set([])\n",
    "        while len(children) < pop_size:\n",
    "            chosen = random.sample(parents,2)\n",
    "            child_weights = []\n",
    "            for arr_0, arr_1 in zip(chosen[0].trainable_weights, \n",
    "                                    chosen[1].trainable_weights):\n",
    "                child_arr = np.zeros(arr_0.shape)\n",
    "                for ((x,y), val_0), (_, val_1) in zip(np.ndenumerate(arr_0), \n",
    "                                                      np.ndenumerate(arr_1)):\n",
    "                    if self.crossover_type=='uniform':\n",
    "                        child_arr[x][y] = random.sample([val_0, val_1],1)\n",
    "                    elif self.crossover_type=='2-point':\n",
    "                        x_range = sorted(random.sample(range(child_arr.shape[0]),2))\n",
    "                        y_range = sorted(random.sample(range(child_arr.shape[1]),2))\n",
    "                        if ((x < x_range[0] and y < y_range[0]) or \n",
    "                            (x > x_range[1] and y > y_range[1])):\n",
    "                            child_arr[x][y] = val_0\n",
    "                        else:\n",
    "                            child_arr[x][y] = val_1\n",
    "                    if random.random() < self.mutation_rate:\n",
    "                        child_arr[x][y] = random.normalvariate(mu=child_arr[x][y], \n",
    "                                                               sigma=self.mutation_sd)\n",
    "                child_weights.append(child_arr)\n",
    "            model = self._build_model(num_inputs, num_outputs)\n",
    "            # idk if get_weights() returns the same object as trainable_weights; test\n",
    "            model.set_weights(child_weights) \n",
    "            children.add(model)\n",
    "            return children            \n",
    "\n",
    "    def fit(self, data, target, num_outputs=1):\n",
    "        \"\"\"Perform genetic local search and return the best model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: vector, matrix, or array of training data. \n",
    "            Passed to Keras' model.fit()\n",
    "        \n",
    "        target: vector, matrix, or array of target data. \n",
    "            Passed to Keras' model.fit()\n",
    "        \n",
    "        num_outputs: int (default=1)\n",
    "            The size the each model's output layer. If performing a \n",
    "            classification task, this value corresponds to the number of \n",
    "            classes.\n",
    "        \"\"\"\n",
    "        \n",
    "        num_inputs = data.shape[1]\n",
    "        population = self._initialize_population(num_inputs, num_outputs)\n",
    "        trained_population = self._local_search(population, data, target)\n",
    "        for _ in range(self.generations):\n",
    "            parents = self._select_parents(trained_population)\n",
    "            population = self._make_children(parents)\n",
    "            trained_population = self._local_search(population, data, target)\n",
    "        return min(trained_population)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next: \n",
    "# write test cases\n",
    "# adaptive algos\n",
    "# make nn params adjustable\n",
    "# write ga to determine best nn params \n",
    "# keep track of population losses for plotting\n",
    "# make it easier to alter nn for regression vs. classification problems, \n",
    "#     e.g. adding softmax activation for output\n",
    "# add more callbacks\n",
    "# error handling\n",
    "# determine a good value for mutation_sd\n",
    "# determine if mutating biases makes sense\n",
    "# add early stopping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
